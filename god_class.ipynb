{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDXYd3l4eGsVPGs6Jsq3uN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahi77/Severity-classification-of-software-code-smells/blob/main/god_class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4iJj0gJVjYw2",
        "outputId": "8ff3f680-0807-4051-84f3-c863d2db0148"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/275.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.6.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.25.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.12.12)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=93c26c8c45eaeda564ff1257a39c5d5d677ce92f88daa17f700656c48cfd9ea0\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install lime\n",
        "\n",
        "import seaborn as sns\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%config InlineBackend.figure_format='retina'\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from operator import itemgetter\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import sklearn\n",
        "import sklearn.datasets\n",
        "import sklearn.ensemble\n",
        "import numpy as np\n",
        "from __future__ import print_function\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "\n",
        "%matplotlib inline\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Load Dataset\n",
        "\n",
        "train_df = pd.read_csv('dataset-god-class.csv', header=0)\n",
        "test_df = pd.read_csv('dataset-god-class.csv', header=0)\n",
        "cols=train_df.columns"
      ],
      "metadata": {
        "id": "3fhfwekyr8gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['source']='train'\n",
        "test_df['source']='test'\n",
        "data = pd.concat([train_df, test_df],ignore_index=True)\n",
        "print (train_df.shape, test_df.shape, data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcN__oIDsADx",
        "outputId": "f91cf8d7-97d0-4f35-9ff3-9aa720965ef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(420, 69) (420, 69) (840, 69)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Divide into test and train:\n",
        "train_df = data.loc[data['source']==\"train\"]\n",
        "test_df = data.loc[data['source']==\"test\"]"
      ],
      "metadata": {
        "id": "se7rwNqYsB96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "V4u5ao5-sDUG",
        "outputId": "c750b62f-ad68-40e1-9ddc-4a1854233b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     dataset      project package         complextype  severity  AMWNAMM_type  \\\n",
              "0  god-class  fitjava-1.1     fat          Frameworks       1.0           2.0   \n",
              "1  god-class  fitjava-1.1     fat   TableParseFixture       1.0           1.0   \n",
              "2  god-class  fitjava-1.1     fat              Divide       1.0           1.0   \n",
              "3  god-class  fitjava-1.1     fat  FixtureNameFixture       1.0           2.0   \n",
              "4  god-class  fitjava-1.1     fat               Table       1.0           1.5   \n",
              "\n",
              "   AMW_type  ATFD_type  CBO_type  CFNAMM_type  ...  \\\n",
              "0       2.0        0.0       5.0          0.0  ...   \n",
              "1       1.0        2.0       5.0          2.0  ...   \n",
              "2       1.0        0.0       5.0          0.0  ...   \n",
              "3       2.0        0.0       5.0          3.0  ...   \n",
              "4       1.5        4.0       5.0          3.0  ...   \n",
              "\n",
              "   number_package_visibility_methods  number_private_visibility_attributes  \\\n",
              "0                                0.0                                   0.0   \n",
              "1                                0.0                                   0.0   \n",
              "2                                0.0                                   0.0   \n",
              "3                                0.0                                   0.0   \n",
              "4                                1.0                                   0.0   \n",
              "\n",
              "   number_private_visibility_methods  number_protected_visibility_attributes  \\\n",
              "0                                0.0                                     0.0   \n",
              "1                                3.0                                     0.0   \n",
              "2                                0.0                                     0.0   \n",
              "3                                3.0                                     0.0   \n",
              "4                                0.0                                     0.0   \n",
              "\n",
              "   number_protected_visibility_methods  number_public_visibility_methods  \\\n",
              "0                                  0.0                               2.0   \n",
              "1                                  0.0                               4.0   \n",
              "2                                  0.0                               1.0   \n",
              "3                                  0.0                               1.0   \n",
              "4                                  0.0                               2.0   \n",
              "\n",
              "   number_standard_design_methods  number_static_methods  visibility_type  \\\n",
              "0                             2.0                    0.0           public   \n",
              "1                             7.0                    0.0           public   \n",
              "2                             1.0                    0.0           public   \n",
              "3                             4.0                    0.0           public   \n",
              "4                             2.0                    1.0           public   \n",
              "\n",
              "   source  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b07899be-f987-4729-82a2-89a2a93c6ae6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>project</th>\n",
              "      <th>package</th>\n",
              "      <th>complextype</th>\n",
              "      <th>severity</th>\n",
              "      <th>AMWNAMM_type</th>\n",
              "      <th>AMW_type</th>\n",
              "      <th>ATFD_type</th>\n",
              "      <th>CBO_type</th>\n",
              "      <th>CFNAMM_type</th>\n",
              "      <th>...</th>\n",
              "      <th>number_package_visibility_methods</th>\n",
              "      <th>number_private_visibility_attributes</th>\n",
              "      <th>number_private_visibility_methods</th>\n",
              "      <th>number_protected_visibility_attributes</th>\n",
              "      <th>number_protected_visibility_methods</th>\n",
              "      <th>number_public_visibility_methods</th>\n",
              "      <th>number_standard_design_methods</th>\n",
              "      <th>number_static_methods</th>\n",
              "      <th>visibility_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Frameworks</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>TableParseFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Divide</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>FixtureNameFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Table</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 69 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b07899be-f987-4729-82a2-89a2a93c6ae6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b07899be-f987-4729-82a2-89a2a93c6ae6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b07899be-f987-4729-82a2-89a2a93c6ae6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7427764b-b8e1-409c-b67b-4860228927c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7427764b-b8e1-409c-b67b-4860228927c4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7427764b-b8e1-409c-b67b-4860228927c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Extract the label column\n",
        "train_target = np.ravel(np.array(train_df['severity'].values))"
      ],
      "metadata": {
        "id": "Tij-fIwTsHVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features\n",
        "float_columns=[]\n",
        "cat_columns=[]\n",
        "int_columns=[]\n",
        "\n",
        "for i in train_df.columns:\n",
        "    if train_df[i].dtype == 'float' :\n",
        "        float_columns.append(i)\n",
        "    elif train_df[i].dtype == 'int64':\n",
        "        int_columns.append(i)\n",
        "    elif train_df[i].dtype == 'object':\n",
        "        cat_columns.append(i)\n",
        "\n",
        "train_cat_features = train_df[cat_columns]\n",
        "train_float_features = train_df[float_columns]\n",
        "train_int_features = train_df[int_columns]"
      ],
      "metadata": {
        "id": "6ICEDsa3sK42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "5pxkCm8ysMEi",
        "outputId": "306cbd37-f2e8-4b0a-c4d0-84e765a9c2f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     dataset      project package         complextype  severity  AMWNAMM_type  \\\n",
              "0  god-class  fitjava-1.1     fat          Frameworks       1.0           2.0   \n",
              "1  god-class  fitjava-1.1     fat   TableParseFixture       1.0           1.0   \n",
              "2  god-class  fitjava-1.1     fat              Divide       1.0           1.0   \n",
              "3  god-class  fitjava-1.1     fat  FixtureNameFixture       1.0           2.0   \n",
              "4  god-class  fitjava-1.1     fat               Table       1.0           1.5   \n",
              "\n",
              "   AMW_type  ATFD_type  CBO_type  CFNAMM_type  ...  \\\n",
              "0       2.0        0.0       5.0          0.0  ...   \n",
              "1       1.0        2.0       5.0          2.0  ...   \n",
              "2       1.0        0.0       5.0          0.0  ...   \n",
              "3       2.0        0.0       5.0          3.0  ...   \n",
              "4       1.5        4.0       5.0          3.0  ...   \n",
              "\n",
              "   number_package_visibility_methods  number_private_visibility_attributes  \\\n",
              "0                                0.0                                   0.0   \n",
              "1                                0.0                                   0.0   \n",
              "2                                0.0                                   0.0   \n",
              "3                                0.0                                   0.0   \n",
              "4                                1.0                                   0.0   \n",
              "\n",
              "   number_private_visibility_methods  number_protected_visibility_attributes  \\\n",
              "0                                0.0                                     0.0   \n",
              "1                                3.0                                     0.0   \n",
              "2                                0.0                                     0.0   \n",
              "3                                3.0                                     0.0   \n",
              "4                                0.0                                     0.0   \n",
              "\n",
              "   number_protected_visibility_methods  number_public_visibility_methods  \\\n",
              "0                                  0.0                               2.0   \n",
              "1                                  0.0                               4.0   \n",
              "2                                  0.0                               1.0   \n",
              "3                                  0.0                               1.0   \n",
              "4                                  0.0                               2.0   \n",
              "\n",
              "   number_standard_design_methods  number_static_methods  visibility_type  \\\n",
              "0                             2.0                    0.0           public   \n",
              "1                             7.0                    0.0           public   \n",
              "2                             1.0                    0.0           public   \n",
              "3                             4.0                    0.0           public   \n",
              "4                             2.0                    1.0           public   \n",
              "\n",
              "   source  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b10f4a7-fb0d-4b00-9ea7-8a0e11296149\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>project</th>\n",
              "      <th>package</th>\n",
              "      <th>complextype</th>\n",
              "      <th>severity</th>\n",
              "      <th>AMWNAMM_type</th>\n",
              "      <th>AMW_type</th>\n",
              "      <th>ATFD_type</th>\n",
              "      <th>CBO_type</th>\n",
              "      <th>CFNAMM_type</th>\n",
              "      <th>...</th>\n",
              "      <th>number_package_visibility_methods</th>\n",
              "      <th>number_private_visibility_attributes</th>\n",
              "      <th>number_private_visibility_methods</th>\n",
              "      <th>number_protected_visibility_attributes</th>\n",
              "      <th>number_protected_visibility_methods</th>\n",
              "      <th>number_public_visibility_methods</th>\n",
              "      <th>number_standard_design_methods</th>\n",
              "      <th>number_static_methods</th>\n",
              "      <th>visibility_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Frameworks</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>TableParseFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Divide</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>FixtureNameFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Table</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 69 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b10f4a7-fb0d-4b00-9ea7-8a0e11296149')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b10f4a7-fb0d-4b00-9ea7-8a0e11296149 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b10f4a7-fb0d-4b00-9ea7-8a0e11296149');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2022f426-97ed-4296-bbcb-fd578f97fca4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2022f426-97ed-4296-bbcb-fd578f97fca4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2022f426-97ed-4296-bbcb-fd578f97fca4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformation of categorical columns\n",
        "# Label Encoding:\n",
        "#train_cat_features_ver2 = pd.get_dummies(train_cat_features, columns=['Destination_Type','Type_of_Cab'])\n",
        "train_cat_features_ver2 = train_cat_features.apply(LabelEncoder().fit_transform)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "T7_AQAH6sO2C",
        "outputId": "c3e5e99a-7014-4554-bb24-d568f124d9a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     dataset      project package         complextype  severity  AMWNAMM_type  \\\n",
              "0  god-class  fitjava-1.1     fat          Frameworks       1.0           2.0   \n",
              "1  god-class  fitjava-1.1     fat   TableParseFixture       1.0           1.0   \n",
              "2  god-class  fitjava-1.1     fat              Divide       1.0           1.0   \n",
              "3  god-class  fitjava-1.1     fat  FixtureNameFixture       1.0           2.0   \n",
              "4  god-class  fitjava-1.1     fat               Table       1.0           1.5   \n",
              "\n",
              "   AMW_type  ATFD_type  CBO_type  CFNAMM_type  ...  \\\n",
              "0       2.0        0.0       5.0          0.0  ...   \n",
              "1       1.0        2.0       5.0          2.0  ...   \n",
              "2       1.0        0.0       5.0          0.0  ...   \n",
              "3       2.0        0.0       5.0          3.0  ...   \n",
              "4       1.5        4.0       5.0          3.0  ...   \n",
              "\n",
              "   number_package_visibility_methods  number_private_visibility_attributes  \\\n",
              "0                                0.0                                   0.0   \n",
              "1                                0.0                                   0.0   \n",
              "2                                0.0                                   0.0   \n",
              "3                                0.0                                   0.0   \n",
              "4                                1.0                                   0.0   \n",
              "\n",
              "   number_private_visibility_methods  number_protected_visibility_attributes  \\\n",
              "0                                0.0                                     0.0   \n",
              "1                                3.0                                     0.0   \n",
              "2                                0.0                                     0.0   \n",
              "3                                3.0                                     0.0   \n",
              "4                                0.0                                     0.0   \n",
              "\n",
              "   number_protected_visibility_methods  number_public_visibility_methods  \\\n",
              "0                                  0.0                               2.0   \n",
              "1                                  0.0                               4.0   \n",
              "2                                  0.0                               1.0   \n",
              "3                                  0.0                               1.0   \n",
              "4                                  0.0                               2.0   \n",
              "\n",
              "   number_standard_design_methods  number_static_methods  visibility_type  \\\n",
              "0                             2.0                    0.0           public   \n",
              "1                             7.0                    0.0           public   \n",
              "2                             1.0                    0.0           public   \n",
              "3                             4.0                    0.0           public   \n",
              "4                             2.0                    1.0           public   \n",
              "\n",
              "   source  \n",
              "0   train  \n",
              "1   train  \n",
              "2   train  \n",
              "3   train  \n",
              "4   train  \n",
              "\n",
              "[5 rows x 69 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-140c20ca-4522-40b0-bdda-0f4ce63ebec9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dataset</th>\n",
              "      <th>project</th>\n",
              "      <th>package</th>\n",
              "      <th>complextype</th>\n",
              "      <th>severity</th>\n",
              "      <th>AMWNAMM_type</th>\n",
              "      <th>AMW_type</th>\n",
              "      <th>ATFD_type</th>\n",
              "      <th>CBO_type</th>\n",
              "      <th>CFNAMM_type</th>\n",
              "      <th>...</th>\n",
              "      <th>number_package_visibility_methods</th>\n",
              "      <th>number_private_visibility_attributes</th>\n",
              "      <th>number_private_visibility_methods</th>\n",
              "      <th>number_protected_visibility_attributes</th>\n",
              "      <th>number_protected_visibility_methods</th>\n",
              "      <th>number_public_visibility_methods</th>\n",
              "      <th>number_standard_design_methods</th>\n",
              "      <th>number_static_methods</th>\n",
              "      <th>visibility_type</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Frameworks</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>TableParseFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Divide</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>FixtureNameFixture</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>god-class</td>\n",
              "      <td>fitjava-1.1</td>\n",
              "      <td>fat</td>\n",
              "      <td>Table</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>public</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 69 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-140c20ca-4522-40b0-bdda-0f4ce63ebec9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-140c20ca-4522-40b0-bdda-0f4ce63ebec9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-140c20ca-4522-40b0-bdda-0f4ce63ebec9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c0c64f86-ea50-4a42-b5e3-60404e14a8fb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c0c64f86-ea50-4a42-b5e3-60404e14a8fb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c0c64f86-ea50-4a42-b5e3-60404e14a8fb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Transformation of float columns\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "for i in train_float_features.columns:\n",
        "    X_temp = train_float_features.loc[:,i].values.reshape(-1,1)\n",
        "    train_float_features.loc[:,i] = scaler.fit_transform(X_temp)"
      ],
      "metadata": {
        "id": "mYT1FQVYsPl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Finalize X & Y\n",
        "temp_1 = np.concatenate((train_cat_features_ver2,train_float_features),axis=1)\n",
        "train_transformed_features = np.concatenate((temp_1,train_int_features),axis=1)\n",
        "train_transformed_features = pd.DataFrame(data=train_transformed_features)\n",
        "train_target = np.ravel(np.array(train_df['severity'].values))\n",
        "\n",
        "array = train_transformed_features.values\n",
        "number_of_features = len(array[0])\n",
        "X = array[:,0:number_of_features]\n",
        "Y = train_target"
      ],
      "metadata": {
        "id": "lKZC9UzSsSnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, mean_absolute_error, mean_squared_error, r2_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, precision_score, recall_score, log_loss\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import xgboost as xgb\n",
        "\n",
        "# Configuration\n",
        "seed = 7\n",
        "splits = {\n",
        "    \"50-50\": 0.5,\n",
        "    \"60-40\": 0.4,\n",
        "    \"70-30\": 0.3,\n",
        "    \"80-20\": 0.2,\n",
        "    \"90-10\": 0.1,\n",
        "}\n",
        "learning_rates = [0.01, 0.1, 0.2, 0.5]  # Example learning rates\n",
        "\n",
        "# Classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"RBF\": SVC(probability=True, kernel='rbf'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naïve Bayes\": GaussianNB(),\n",
        "    \"AdaBoost\": AdaBoostClassifier(),\n",
        "    # Uncomment if XGBoost is available\n",
        "    # \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss'),\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "data_splits = {}\n",
        "results = {}\n",
        "\n",
        "# Split the dataset\n",
        "for split_name, test_size in splits.items():\n",
        "    X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "    data_splits[split_name] = {\n",
        "        \"X_train\": X_train,\n",
        "        \"X_validation\": X_validation,\n",
        "        \"Y_train\": Y_train,\n",
        "        \"Y_validation\": Y_validation,\n",
        "    }\n",
        "\n",
        "# Evaluation\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_validation = imputer.transform(X_validation)\n",
        "\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "    # Store results for each classifier\n",
        "    results[split_name] = {}\n",
        "\n",
        "    for clf_name, model in classifiers.items():\n",
        "        for lr in learning_rates:\n",
        "            if hasattr(model, \"learning_rate\"):\n",
        "                model.set_params(learning_rate=lr)\n",
        "\n",
        "            start_time = time.time()\n",
        "            model.fit(X_train, Y_train)\n",
        "\n",
        "            # Predictions\n",
        "            predictions = model.predict(X_validation)\n",
        "            prob_predictions = model.predict_proba(X_validation) if hasattr(model, \"predict_proba\") else None\n",
        "\n",
        "            end_time = time.time()\n",
        "            computation_time = end_time - start_time\n",
        "\n",
        "            # Metrics\n",
        "            accuracy = accuracy_score(Y_validation, predictions)\n",
        "            f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "            precision = precision_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "            recall = recall_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "            log_loss_value = log_loss(Y_validation, prob_predictions) if prob_predictions is not None else np.nan\n",
        "            roc_auc = roc_auc_score(Y_validation, prob_predictions[:, 1]) if prob_predictions is not None and len(np.unique(Y_validation)) == 2 else np.nan\n",
        "            mae = mean_absolute_error(Y_validation, predictions)\n",
        "            mse = mean_squared_error(Y_validation, predictions)\n",
        "            rmse = np.sqrt(mse)\n",
        "            r_squared = r2_score(Y_validation, predictions)\n",
        "\n",
        "            # Save results\n",
        "            results[split_name][f\"{clf_name} (lr={lr})\"] = {\n",
        "                \"Accuracy\": accuracy,\n",
        "                \"Precision\": precision,\n",
        "                \"Recall\": recall,\n",
        "                \"F1 Score\": f1,\n",
        "                \"Log Loss\": log_loss_value,\n",
        "                \"ROC AUC\": roc_auc,\n",
        "                \"MAE\": mae,\n",
        "                \"MSE\": mse,\n",
        "                \"RMSE\": rmse,\n",
        "                \"R-Squared\": r_squared,\n",
        "                \"Computation Time\": computation_time,\n",
        "            }\n",
        "\n",
        "# Export to Excel\n",
        "excel_data = []\n",
        "for split_name, models in results.items():\n",
        "    for clf_name, metrics in models.items():\n",
        "        row = {\"Split Name\": split_name, \"Model\": clf_name}\n",
        "        row.update(metrics)\n",
        "        excel_data.append(row)\n",
        "\n",
        "df = pd.DataFrame(excel_data)\n",
        "output_file = 'results_with_learning_rates.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Results saved to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZTu7RW4Y4F",
        "outputId": "b8ede0b5-a152-4566-fda6-38bb3370e52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to results_with_learning_rates.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and validation sets for multiple sizes\n",
        "seed = 7\n",
        "splits = {\n",
        "    \"50-50\": 0.5,\n",
        "    \"60-40\": 0.4,\n",
        "    \"70-30\": 0.3,\n",
        "    \"80-20\": 0.2,\n",
        "    \"90-10\": 0.1,\n",
        "}\n",
        "\n",
        "# Dictionary to hold the results\n",
        "data_splits = {}\n",
        "\n",
        "for split_name, test_size in splits.items():\n",
        "    X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "    data_splits[split_name] = {\n",
        "        \"X_train\": X_train,\n",
        "        \"X_validation\": X_validation,\n",
        "        \"Y_train\": Y_train,\n",
        "        \"Y_validation\": Y_validation,\n",
        "    }"
      ],
      "metadata": {
        "id": "oKly9d1_sVRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest Classifier\n",
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X_train, Y_train)\n",
        "accuracy_score(Y_validation, model_rf.predict(X_validation))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2I7reXTsYOA",
        "outputId": "03a372c8-526d-4bf9-b665-7b74ad6d4dce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Model 1 - RandomForest Classifier\n",
        "    model_rf = RandomForestClassifier()\n",
        "    model_rf.fit(X_train, Y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(Y_validation, model_rf.predict(X_validation))\n",
        "\n",
        "    # Store the accuracy result for each split\n",
        "    results[split_name] = accuracy\n",
        "\n",
        "# Print the results for each split\n",
        "for split_name, accuracy in results.items():\n",
        "    print(f'Accuracy for {split_name}: {accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILixLXoY5oUU",
        "outputId": "b3598e3f-5077-4868-ac28-761066b4832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for 50-50: 0.8904761904761904\n",
            "Accuracy for 60-40: 0.8511904761904762\n",
            "Accuracy for 70-30: 0.8888888888888888\n",
            "Accuracy for 80-20: 0.8690476190476191\n",
            "Accuracy for 90-10: 0.8571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (accuracy_score, mean_absolute_error, mean_squared_error, r2_score,\n",
        "                             confusion_matrix, f1_score, roc_curve, roc_auc_score)\n",
        "import time\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Model 1 - RandomForest Classifier\n",
        "    model_rf = RandomForestClassifier()\n",
        "\n",
        "    # Start time measurement\n",
        "    start_time = time.time()\n",
        "\n",
        "    model_rf.fit(X_train, Y_train)\n",
        "\n",
        "    # Predictions\n",
        "    predictions = model_rf.predict(X_validation)\n",
        "\n",
        "    # Stop time measurement\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "\n",
        "    # Evaluation Metrics\n",
        "    accuracy = accuracy_score(Y_validation, predictions)\n",
        "    mae = mean_absolute_error(Y_validation, predictions)\n",
        "    mse = mean_squared_error(Y_validation, predictions)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r_squared = r2_score(Y_validation, predictions)\n",
        "    mape = np.mean(np.abs((Y_validation - predictions) / Y_validation)) * 100 if np.all(Y_validation) else np.nan\n",
        "    f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "    cm = confusion_matrix(Y_validation, predictions)\n",
        "\n",
        "    # PRED (25): The percentage of predictions that are correct\n",
        "    pred_25 = np.mean(predictions >= 25) * 100  # Assuming predictions are numerical\n",
        "\n",
        "    # Adjusted R-Squared\n",
        "    n = len(Y_validation)  # Number of observations\n",
        "    p = X_validation.shape[1]  # Number of features\n",
        "    adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "\n",
        "    # Mean Bias Deviation (MBD)\n",
        "    mbd = np.mean(predictions - Y_validation)\n",
        "\n",
        "    # Coefficient of Variation (CV)\n",
        "    cv = np.std(predictions) / np.mean(predictions) if np.mean(predictions) != 0 else np.nan\n",
        "\n",
        "    # Store results for each split\n",
        "    results[split_name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R-Squared\": r_squared,\n",
        "        \"Computation Time\": computation_time,\n",
        "        \"MAPE\": mape,\n",
        "        \"Adjusted R-Squared\": adjusted_r_squared,\n",
        "        \"MBD\": mbd,\n",
        "        \"CV\": cv,\n",
        "        \"F1 Score\": f1,\n",
        "        \"Confusion Matrix\": cm,\n",
        "        \"ROC AUC\": roc_auc_score(Y_validation, model_rf.predict_proba(X_validation)[:, 1]) if len(np.unique(Y_validation)) == 2 else np.nan,\n",
        "    }\n",
        "\n",
        "# Print the results for each split\n",
        "for split_name, metrics in results.items():\n",
        "    print(f'Results for {split_name}:')\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        print(f'{metric_name}: {metric_value}')\n",
        "    print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhNo4s_G7HU2",
        "outputId": "b13eb31c-1412-4990-fb9a-23e557f56aef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for 50-50:\n",
            "Accuracy: 0.8666666666666667\n",
            "MAE: 0.1523809523809524\n",
            "MSE: 0.19047619047619047\n",
            "RMSE: 0.4364357804719847\n",
            "R-Squared: 0.8835274542429284\n",
            "Computation Time: 0.1968693733215332\n",
            "MAPE: 6.785714285714286\n",
            "Adjusted R-Squared: 0.8261231281198003\n",
            "MBD: -0.02857142857142857\n",
            "CV: 0.5034075695495948\n",
            "F1 Score: 0.8583691619066575\n",
            "Confusion Matrix: [[72  0  2  0]\n",
            " [ 5  4  5  0]\n",
            " [ 2  1 43  4]\n",
            " [ 0  0  9 63]]\n",
            "ROC AUC: nan\n",
            "\n",
            "\n",
            "Results for 60-40:\n",
            "Accuracy: 0.8809523809523809\n",
            "MAE: 0.13095238095238096\n",
            "MSE: 0.15476190476190477\n",
            "RMSE: 0.3933978962347216\n",
            "R-Squared: 0.9072355427187971\n",
            "Computation Time: 0.20417308807373047\n",
            "MAPE: 6.398809523809524\n",
            "Adjusted R-Squared: 0.8419217921840727\n",
            "MBD: -0.011904761904761904\n",
            "CV: 0.4847414125277737\n",
            "F1 Score: 0.8746890488534372\n",
            "Confusion Matrix: [[56  0  2  0]\n",
            " [ 3  4  6  0]\n",
            " [ 0  0 35  0]\n",
            " [ 0  0  9 53]]\n",
            "ROC AUC: nan\n",
            "\n",
            "\n",
            "Results for 70-30:\n",
            "Accuracy: 0.8888888888888888\n",
            "MAE: 0.1111111111111111\n",
            "MSE: 0.1111111111111111\n",
            "RMSE: 0.3333333333333333\n",
            "R-Squared: 0.9317759900990099\n",
            "Computation Time: 0.2174513339996338\n",
            "MAPE: 3.835978835978836\n",
            "Adjusted R-Squared: 0.8477142636138614\n",
            "MBD: -0.047619047619047616\n",
            "CV: 0.4777798152745408\n",
            "F1 Score: 0.8859680335357931\n",
            "Confusion Matrix: [[42  0  0  0]\n",
            " [ 1  3  4  0]\n",
            " [ 0  1 29  0]\n",
            " [ 0  0  8 38]]\n",
            "ROC AUC: nan\n",
            "\n",
            "\n",
            "Results for 80-20:\n",
            "Accuracy: 0.8571428571428571\n",
            "MAE: 0.15476190476190477\n",
            "MSE: 0.17857142857142858\n",
            "RMSE: 0.4225771273642583\n",
            "R-Squared: 0.8956521739130435\n",
            "Computation Time: 0.20628952980041504\n",
            "MAPE: 6.349206349206349\n",
            "Adjusted R-Squared: 0.3813664596273295\n",
            "MBD: -0.03571428571428571\n",
            "CV: 0.45681461636110654\n",
            "F1 Score: 0.8644720818957454\n",
            "Confusion Matrix: [[26  0  1  0]\n",
            " [ 0  2  2  0]\n",
            " [ 0  0 15  1]\n",
            " [ 0  0  8 29]]\n",
            "ROC AUC: nan\n",
            "\n",
            "\n",
            "Results for 90-10:\n",
            "Accuracy: 0.7857142857142857\n",
            "MAE: 0.2619047619047619\n",
            "MSE: 0.35714285714285715\n",
            "RMSE: 0.5976143046671968\n",
            "R-Squared: 0.7585281717133001\n",
            "Computation Time: 0.21597647666931152\n",
            "MAPE: 15.079365079365079\n",
            "Adjusted R-Squared: 1.3535837485626678\n",
            "MBD: 0.07142857142857142\n",
            "CV: 0.390198794346486\n",
            "F1 Score: 0.7758537758537759\n",
            "Confusion Matrix: [[10  0  2  0]\n",
            " [ 0  0  2  0]\n",
            " [ 0  0 12  1]\n",
            " [ 0  0  4 11]]\n",
            "ROC AUC: nan\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC as SVC_RBF\n",
        "import xgboost as xgb\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "# Define the classifiers you want to evaluate, including AdaBoost\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"RBF\": SVC_RBF(probability=True, kernel='rbf'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naïve Bayes\": GaussianNB(),\n",
        "    \"XGBoost\": AdaBoostClassifier(),  # Added AdaBoost Classifier\n",
        "    # \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss'),\n",
        "}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_validation = imputer.transform(X_validation)\n",
        "\n",
        "    # Apply SMOTE for class balancing\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train, Y_train = smote.fit_resample(X_train, Y_train)\n",
        "\n",
        "    # Store results for each classifier\n",
        "    results[split_name] = {}\n",
        "\n",
        "    for clf_name, model in classifiers.items():\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = model.predict(X_validation)\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            prob_predictions = model.predict_proba(X_validation)\n",
        "        else:\n",
        "            prob_predictions = None\n",
        "\n",
        "        end_time = time.time()\n",
        "        computation_time = end_time - start_time\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        accuracy = accuracy_score(Y_validation, predictions)\n",
        "        mae = mean_absolute_error(Y_validation, predictions)\n",
        "        mse = mean_squared_error(Y_validation, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r_squared = r2_score(Y_validation, predictions)\n",
        "        mape = np.mean(np.abs((Y_validation - predictions) / Y_validation)) * 100 if np.all(Y_validation) else np.nan\n",
        "        f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "        cm = confusion_matrix(Y_validation, predictions)\n",
        "\n",
        "        precision = precision_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        recall = recall_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        log_loss_value = log_loss(Y_validation, prob_predictions) if prob_predictions is not None else np.nan\n",
        "        roc_auc = roc_auc_score(Y_validation, prob_predictions[:, 1]) if prob_predictions is not None and len(np.unique(Y_validation)) == 2 else np.nan\n",
        "\n",
        "        pred_25 = np.mean(predictions >= 25) * 100\n",
        "        n = len(Y_validation)\n",
        "        p = X_validation.shape[1]\n",
        "        adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "        mbd = np.mean(predictions - Y_validation)\n",
        "        cv = np.std(predictions) / np.mean(predictions) if np.mean(predictions) != 0 else np.nan\n",
        "\n",
        "        # Store results for this model\n",
        "        results[split_name][clf_name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"Log Loss\": log_loss_value,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"RMSE\": rmse,\n",
        "            \"R-Squared\": r_squared,\n",
        "            \"Computation Time\": computation_time,\n",
        "            \"MAPE\": mape,\n",
        "            \"Adjusted R-Squared\": adjusted_r_squared,\n",
        "            \"MBD\": mbd,\n",
        "            \"CV\": cv,\n",
        "        }\n",
        "\n",
        "# Prepare data for Excel export\n",
        "excel_data = []\n",
        "for split_name, models in results.items():\n",
        "    for clf_name, metrics in models.items():\n",
        "        row = {\"Split Name\": split_name, \"Model\": clf_name}\n",
        "        row.update(metrics)\n",
        "        excel_data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(excel_data)\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file = 'model_evaluation_results_with_smote_and_adaboost.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f'Results saved to {output_file}')\n"
      ],
      "metadata": {
        "id": "iX95dnfNohp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516ca311-4acf-4af4-aaa4-0f5c4fd19e11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to model_evaluation_results_with_smote_and_adaboost.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC as SVC_RBF\n",
        "import xgboost as xgb\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "# Define the classifiers you want to evaluate\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"RBF\": SVC_RBF(probability=True, kernel='rbf'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naïve Bayes\": GaussianNB(),\n",
        "    # \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss'),\n",
        "}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')  # or another strategy\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_validation = imputer.transform(X_validation)\n",
        "\n",
        "    # Store results for each classifier\n",
        "    results[split_name] = {}\n",
        "\n",
        "    for clf_name, model in classifiers.items():\n",
        "        # Start time measurement\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Y_train = (Y_train - 1).astype(int)  # Assuming classes are in the range [1, 2, 3, 4]\n",
        "        # Y_validation = (Y_validation - 1).astype(int)\n",
        "\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = model.predict(X_validation)\n",
        "        # For log_loss, we need the probability estimates\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            prob_predictions = model.predict_proba(X_validation)\n",
        "        else:\n",
        "            prob_predictions = None\n",
        "\n",
        "        # Stop time measurement\n",
        "        end_time = time.time()\n",
        "        computation_time = end_time - start_time\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        accuracy = accuracy_score(Y_validation, predictions)\n",
        "        mae = mean_absolute_error(Y_validation, predictions)\n",
        "        mse = mean_squared_error(Y_validation, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r_squared = r2_score(Y_validation, predictions)\n",
        "        mape = np.mean(np.abs((Y_validation - predictions) / Y_validation)) * 100 if np.all(Y_validation) else np.nan\n",
        "        f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "        cm = confusion_matrix(Y_validation, predictions)\n",
        "\n",
        "        # Additional Metrics\n",
        "        precision = precision_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        recall = recall_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        log_loss_value = log_loss(Y_validation, prob_predictions) if prob_predictions is not None else np.nan\n",
        "        roc_auc = roc_auc_score(Y_validation, prob_predictions[:, 1]) if prob_predictions is not None and len(np.unique(Y_validation)) == 2 else np.nan\n",
        "\n",
        "        # PRED (25): The percentage of predictions that are correct\n",
        "        pred_25 = np.mean(predictions >= 25) * 100  # Assuming predictions are numerical\n",
        "\n",
        "        # Adjusted R-Squared\n",
        "        n = len(Y_validation)  # Number of observations\n",
        "        p = X_validation.shape[1]  # Number of features\n",
        "        adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "\n",
        "        # Mean Bias Deviation (MBD)\n",
        "        mbd = np.mean(predictions - Y_validation)\n",
        "\n",
        "        # Coefficient of Variation (CV)\n",
        "        cv = np.std(predictions) / np.mean(predictions) if np.mean(predictions) != 0 else np.nan\n",
        "\n",
        "        # Store results for this model\n",
        "        results[split_name][clf_name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"F1 Score\": f1,\n",
        "            \"Confusion Matrix\": cm,\n",
        "            \"Log Loss\": log_loss_value,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"RMSE\": rmse,\n",
        "            \"R-Squared\": r_squared,\n",
        "            \"Computation Time\": computation_time,\n",
        "            \"MAPE\": mape,\n",
        "            \"Adjusted R-Squared\": adjusted_r_squared,\n",
        "            \"MBD\": mbd,\n",
        "            \"CV\": cv,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "        }\n",
        "\n",
        "# Prepare data for Excel export\n",
        "excel_data = []\n",
        "for split_name, models in results.items():\n",
        "    for clf_name, metrics in models.items():\n",
        "        row = {\"Split Name\": split_name, \"Model\": clf_name}\n",
        "        row.update(metrics)\n",
        "        excel_data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(excel_data)\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file = 'model_evaluation_results_with_metrics_gc.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f'Results saved to {output_file}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqFxpZGnGCJO",
        "outputId": "6fff84b2-ab7e-4503-87da-259a02d166e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ad6dc7239a54>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1475\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0mn_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n\u001b[0m\u001b[1;32m   1351\u001b[0m             path_func(\n\u001b[1;32m   1352\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         )\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m             ]\n\u001b[0;32m--> 455\u001b[0;31m             opt_res = optimize.minimize(\n\u001b[0m\u001b[1;32m    456\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    711\u001b[0m                                  **options)\n\u001b[1;32m    712\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    714\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    715\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_linear_loss.py\u001b[0m in \u001b[0;36mloss_gradient\u001b[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[1;32m    286\u001b[0m         )\n\u001b[1;32m    287\u001b[0m         \u001b[0msw_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msw_sum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_penalty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg_strength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     48\u001b[0m          initial=_NoValue, where=True):\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "# Define the classifiers you want to evaluate\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')  # or another strategy\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_validation = imputer.transform(X_validation)\n",
        "\n",
        "    # Store results for each classifier\n",
        "    results[split_name] = {}\n",
        "\n",
        "    for clf_name, model in classifiers.items():\n",
        "        # Start time measurement\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = model.predict(X_validation)\n",
        "\n",
        "        # Stop time measurement\n",
        "        end_time = time.time()\n",
        "        computation_time = end_time - start_time\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        accuracy = accuracy_score(Y_validation, predictions)\n",
        "        mae = mean_absolute_error(Y_validation, predictions)\n",
        "        mse = mean_squared_error(Y_validation, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r_squared = r2_score(Y_validation, predictions)\n",
        "        mape = np.mean(np.abs((Y_validation - predictions) / Y_validation)) * 100 if np.all(Y_validation) else np.nan\n",
        "        f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "        cm = confusion_matrix(Y_validation, predictions)\n",
        "\n",
        "        # PRED (25): The percentage of predictions that are correct\n",
        "        pred_25 = np.mean(predictions >= 25) * 100  # Assuming predictions are numerical\n",
        "\n",
        "        # Adjusted R-Squared\n",
        "        n = len(Y_validation)  # Number of observations\n",
        "        p = X_validation.shape[1]  # Number of features\n",
        "        adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "\n",
        "        # Mean Bias Deviation (MBD)\n",
        "        mbd = np.mean(predictions - Y_validation)\n",
        "\n",
        "        # Coefficient of Variation (CV)\n",
        "        cv = np.std(predictions) / np.mean(predictions) if np.mean(predictions) != 0 else np.nan\n",
        "\n",
        "        # Store results for this model\n",
        "        results[split_name][clf_name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"RMSE\": rmse,\n",
        "            \"R-Squared\": r_squared,\n",
        "            \"Computation Time\": computation_time,\n",
        "            \"MAPE\": mape,\n",
        "            \"Adjusted R-Squared\": adjusted_r_squared,\n",
        "            \"MBD\": mbd,\n",
        "            \"CV\": cv,\n",
        "            \"F1 Score\": f1,\n",
        "            \"Confusion Matrix\": cm,\n",
        "            \"ROC AUC\": roc_auc_score(Y_validation, model.predict_proba(X_validation)[:, 1]) if len(np.unique(Y_validation)) == 2 else np.nan,\n",
        "        }\n",
        "\n",
        "# Print the results for each split\n",
        "for split_name, models in results.items():\n",
        "    print(f'Results for {split_name}:')\n",
        "    for clf_name, metrics in models.items():\n",
        "        print(f'\\nModel: {clf_name}')\n",
        "        for metric_name, metric_value in metrics.items():\n",
        "            print(f'{metric_name}: {metric_value}')\n"
      ],
      "metadata": {
        "id": "v6OTcVYx7M62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, f1_score, confusion_matrix, roc_auc_score, precision_score, recall_score, log_loss\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC as SVC_RBF\n",
        "import xgboost as xgb\n",
        "\n",
        "# Assume data_splits is already created as shown before\n",
        "results = {}\n",
        "\n",
        "# Define the classifiers you want to evaluate\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"Support Vector Machine (RBF)\": SVC_RBF(probability=True, kernel='rbf'),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naïve Bayes\": GaussianNB(),\n",
        "    \"XGBoost\": xgb.XGBClassifier(eval_metric='mlogloss'),\n",
        "}\n",
        "\n",
        "for split_name, split_data in data_splits.items():\n",
        "    X_train = split_data[\"X_train\"]\n",
        "    X_validation = split_data[\"X_validation\"]\n",
        "    Y_train = split_data[\"Y_train\"]\n",
        "    Y_validation = split_data[\"Y_validation\"]\n",
        "\n",
        "    # Handle missing values\n",
        "    imputer = SimpleImputer(strategy='mean')  # or another strategy\n",
        "    X_train = imputer.fit_transform(X_train)\n",
        "    X_validation = imputer.transform(X_validation)\n",
        "\n",
        "    # Store results for each classifier\n",
        "    results[split_name] = {}\n",
        "\n",
        "    for clf_name, model in classifiers.items():\n",
        "        # Start time measurement\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "\n",
        "        # Predictions\n",
        "        predictions = model.predict(X_validation)\n",
        "        # For log_loss, we need the probability estimates\n",
        "        if hasattr(model, \"predict_proba\"):\n",
        "            prob_predictions = model.predict_proba(X_validation)\n",
        "        else:\n",
        "            prob_predictions = None\n",
        "\n",
        "        # Stop time measurement\n",
        "        end_time = time.time()\n",
        "        computation_time = end_time - start_time\n",
        "\n",
        "        # Evaluation Metrics\n",
        "        accuracy = accuracy_score(Y_validation, predictions)\n",
        "        mae = mean_absolute_error(Y_validation, predictions)\n",
        "        mse = mean_squared_error(Y_validation, predictions)\n",
        "        rmse = np.sqrt(mse)\n",
        "        r_squared = r2_score(Y_validation, predictions)\n",
        "        mape = np.mean(np.abs((Y_validation - predictions) / Y_validation)) * 100 if np.all(Y_validation) else np.nan\n",
        "        f1 = f1_score(Y_validation, predictions, average='weighted')\n",
        "        cm = confusion_matrix(Y_validation, predictions)\n",
        "\n",
        "        # Additional Metrics\n",
        "        precision = precision_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        recall = recall_score(Y_validation, predictions, average='weighted', zero_division=0)\n",
        "        log_loss_value = log_loss(Y_validation, prob_predictions) if prob_predictions is not None else np.nan\n",
        "        roc_auc = roc_auc_score(Y_validation, prob_predictions[:, 1]) if prob_predictions is not None and len(np.unique(Y_validation)) == 2 else np.nan\n",
        "\n",
        "        # PRED (25): The percentage of predictions that are correct\n",
        "        pred_25 = np.mean(predictions >= 25) * 100  # Assuming predictions are numerical\n",
        "\n",
        "        # Adjusted R-Squared\n",
        "        n = len(Y_validation)  # Number of observations\n",
        "        p = X_validation.shape[1]  # Number of features\n",
        "        adjusted_r_squared = 1 - (1 - r_squared) * (n - 1) / (n - p - 1)\n",
        "\n",
        "        # Mean Bias Deviation (MBD)\n",
        "        mbd = np.mean(predictions - Y_validation)\n",
        "\n",
        "        # Coefficient of Variation (CV)\n",
        "        cv = np.std(predictions) / np.mean(predictions) if np.mean(predictions) != 0 else np.nan\n",
        "\n",
        "        # Store results for this model\n",
        "        results[split_name][clf_name] = {\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"MAE\": mae,\n",
        "            \"MSE\": mse,\n",
        "            \"RMSE\": rmse,\n",
        "            \"R-Squared\": r_squared,\n",
        "            \"Computation Time\": computation_time,\n",
        "            \"MAPE\": mape,\n",
        "            \"Adjusted R-Squared\": adjusted_r_squared,\n",
        "            \"MBD\": mbd,\n",
        "            \"CV\": cv,\n",
        "            \"F1 Score\": f1,\n",
        "            \"Confusion Matrix\": cm,\n",
        "            \"Precision\": precision,\n",
        "            \"Recall\": recall,\n",
        "            \"Log Loss\": log_loss_value,\n",
        "            \"ROC AUC\": roc_auc,\n",
        "        }\n",
        "\n",
        "# Prepare data for Excel export\n",
        "excel_data = []\n",
        "for split_name, models in results.items():\n",
        "    for clf_name, metrics in models.items():\n",
        "        row = {\"Split Name\": split_name, \"Model\": clf_name}\n",
        "        row.update(metrics)\n",
        "        excel_data.append(row)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(excel_data)\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "output_file = 'model_evaluation_results_with_metrics.xlsx'\n",
        "df.to_excel(output_file, index=False)\n",
        "\n",
        "print(f'Results saved to {output_file}')\n"
      ],
      "metadata": {
        "id": "WIoDOTv6957f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_rf = RandomForestClassifier()\n",
        "model_rf.fit(X, Y)"
      ],
      "metadata": {
        "id": "vDIkCAyr5mm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names_cat = list(train_cat_features_ver2)\n",
        "feature_names_float = list(train_float_features)\n",
        "feature_names_int = list(train_int_features)\n",
        "\n",
        "feature_names = sum([feature_names_cat, feature_names_float, feature_names_int], [])\n",
        "print(feature_names)"
      ],
      "metadata": {
        "id": "tDNxxxo9sbSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = lime.lime_tabular.LimeTabularExplainer(X_train ,feature_names = feature_names,class_names=['1','2','3'],\n",
        "                                                   categorical_features=cat_columns,\n",
        "                                                   categorical_names=feature_names_cat, kernel_width=3)"
      ],
      "metadata": {
        "id": "BZDQMSRPscud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick the observation in the validation set for which explanation is required\n",
        "observation_1 = 2"
      ],
      "metadata": {
        "id": "uMSswcsUsehk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_fn_logreg = lambda x: model_logreg.predict_proba(x).astype(float)\n",
        "predict_fn_rf = lambda x: model_rf.predict_proba(x).astype(float)\n",
        "predict_fn_xgb = lambda x: model_xgb.predict_proba(x).astype(float)"
      ],
      "metadata": {
        "id": "OGlzSY_zsgBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the explanation for RandomForest\n",
        "observation_1 = 4\n",
        "exp = explainer.explain_instance(X_validation[observation_1], predict_fn_rf, num_features=6)\n",
        "exp.show_in_notebook(show_all=True)\n",
        "exp.as_pyplot_figure()"
      ],
      "metadata": {
        "id": "r1Dp0bHzshdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_logreg = LogisticRegression()\n",
        "model_logreg.fit(X_train, Y_train)\n",
        "accuracy_score(Y_validation, model_logreg.predict(X_validation))"
      ],
      "metadata": {
        "id": "rIsxxA-6sj1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "model_logreg = LogisticRegression()\n",
        "model_logreg.fit(X_train, Y_train)\n",
        "\n",
        "predictions = model_logreg.predict(X_validation)\n",
        "\n",
        "accuracy = accuracy_score(Y_validation, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(Y_validation, predictions))\n"
      ],
      "metadata": {
        "id": "v9EFRXuq51lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_logreg = LogisticRegression()\n",
        "model_logreg.fit(X, Y)"
      ],
      "metadata": {
        "id": "rpZ-9ItAslTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_fn_logreg = lambda x: model_logreg.predict_proba(x).astype(float)"
      ],
      "metadata": {
        "id": "vzTrHpPlsnKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_validation[observation_1])"
      ],
      "metadata": {
        "id": "3rMuOdWjso0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick the observation in the validation set for which explanation is required\n",
        "observation_2 = 45"
      ],
      "metadata": {
        "id": "5w0Jezi5sqVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "id": "PG0UJch15_YM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "Y_train = Y_train.astype(int)\n",
        "Y_validation = Y_validation.astype(int)\n",
        "\n",
        "Y_train = Y_train - 1\n",
        "Y_validation = Y_validation - 1\n",
        "\n",
        "model_xgb = XGBClassifier()\n",
        "model_xgb.fit(X_train, Y_train)\n",
        "\n",
        "accuracy = accuracy_score(Y_validation, model_xgb.predict(X_validation))\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "3Iv0GGSM6DKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "predictions = model_xgb.predict(X_validation)\n",
        "print(confusion_matrix(Y_validation, predictions))\n",
        "print(classification_report(Y_validation, predictions))"
      ],
      "metadata": {
        "id": "DROikD7Z6Knn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}